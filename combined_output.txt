=== ./model.py ===
import torch
import torch.nn as nn
import torch.nn.functional as F

class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        # Convolutional layers
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(6)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)
        self.bn2 = nn.BatchNorm2d(16)
        
        # Fully connected layers
        self.fc1 = nn.Linear(400, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
        # Max pooling layers
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        # First convolutional layer
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.pool(x)
        
        # Second convolutional layer
        x = self.conv2(x)
        x = self.bn2(x)
        x = F.relu(x)
        x = self.pool(x)
        
        # Flatten
        x = x.view(x.size(0), -1)
        
        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x


=== ./README.md ===



=== ./dataset.py ===
# dataset.py
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

def get_mnist_data(batch_size=32, train_val_split=0.9):
    # Define transformations
    transform = transforms.Compose([
        transforms.Resize((32, 32)),  # LeNet-5 expects 32x32 images
        transforms.ToTensor(),
    ])
    
    # Download MNIST dataset
    train_dataset = datasets.MNIST(root='./data', 
                                 train=True,
                                 transform=transform,
                                 download=True)
    
    test_dataset = datasets.MNIST(root='./data', 
                                train=False,
                                transform=transform,
                                download=True)
    
    # Split training data into train and validation sets
    train_size = int(len(train_dataset) * train_val_split)
    val_size = len(train_dataset) - train_size
    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])
    
    # Create data loaders
    train_loader = DataLoader(train_dataset, 
                            batch_size=batch_size,
                            shuffle=True)
    
    val_loader = DataLoader(val_dataset,
                          batch_size=batch_size,
                          shuffle=False)
    
    test_loader = DataLoader(test_dataset,
                           batch_size=batch_size,
                           shuffle=False)
    
    return train_loader, val_loader, test_loader


=== ./loss.py ===
import torch.nn as nn
import torch.optim as optim

class TrainingConfig:
    def __init__(self, model, learning_rate=0.001):
        self.model = model
        self.criterion = nn.CrossEntropyLoss()  # Loss function
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)  # Optimizer

    def compute_loss(self, outputs, targets):
        return self.criterion(outputs, targets)



=== ./train.py ===
import torch
from model import LeNet5
from dataset import get_mnist_data
from loss import TrainingConfig

def train_epoch(model, train_loader, config, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)

        config.optimizer.zero_grad()  # Zero gradients
        outputs = model(inputs)
        loss = config.compute_loss(outputs, targets)
        loss.backward()  # Backpropagation
        config.optimizer.step()  # Update weights

        running_loss += loss.item()
        _, predicted = outputs.max(1)  # Get predictions

        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

    return running_loss / len(train_loader), 100. * correct / total

def validate(model, val_loader, config, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, targets in val_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = config.compute_loss(outputs, targets)

            running_loss += loss.item()
            _, predicted = outputs.max(1)  # Get predictions
            
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    return running_loss / len(val_loader), 100. * correct / total

def train():
    # Setup device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Initialize model
    model = LeNet5().to(device)
    
    # Get data loaders
    train_loader, val_loader, test_loader = get_mnist_data()
    
    # Setup training configuration
    config = TrainingConfig(model)
    
    # Training loop
    num_epochs = 10
    for epoch in range(num_epochs):
        train_loss, train_acc = train_epoch(model, train_loader, config, device)
        val_loss, val_acc = validate(model, val_loader, config, device)
        
        print(f'Epoch: {epoch+1}/{num_epochs}')
        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')
        print('-' * 50)

    # Save the trained model weights
    torch.save(model.state_dict(), './weights/lenet5.pth')





=== ./inference.py ===
import torch
import torch.nn.functional as F
from PIL import Image
import numpy as np
from torchvision import transforms
from model import LeNet5
import os
from typing import Union, List, Tuple


class LeNet5Inferencer:
    def __init__(self, model_path: str, device: str=None):
        """
        Initialize the inference with a trained model
        Args:
            model_path: Path to the saved model weights
            device: Device to run inference on ('cuda' or 'cpu')
        """
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)

        # Initialize the model
        self.model = LeNet5().to(self.device)

        # Load model weights
        if os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=self.device, weights_only=True))
        else:
            raise FileNotFoundError(f"No model found at {model_path}")
        
        # Set model to evaluation mode
        self.model.eval()

        # Define transforms
        self.transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1), # Convert to grayscale
            transforms.Resize((32, 32)),
            transforms.ToTensor(),
        ])

    def preprocess_image(self, image_path: str) -> torch.Tensor:
        """
        Preprocess a single image for inference

        Args: 
            image_path: Path to the image file
        
        Returns:
            Preprocessed image tensor
        """
        # Load and preprocess image
        image = Image.open(image_path)
        image_tensor = self.transform(image)
        # Add batch dimension
        image_tensor = image_tensor.unsqueeze(0)
        return image_tensor.to(self.device)
    

    def predict_single(self, image_path: str, return_confidence: bool = False) -> Union[int, Tuple[int, float]]:
        """
        Make prediction on a single image

        Args: 
            image_path: Path to the image file
            return_confidence: Whether to return confidence score

        Returns:
            Predicted class (and confidence score if return_confidence True)
        """
        # Preprocess image
        image_tensor = self.preprocess_image(image_path)

        with torch.no_grad():
            # Get model prediction
            outputs = self.model(image_tensor)
            probabilities = F.softmax(outputs, dim=1)

            # Get predicted class and confidence
            confidence, predicted = torch.max(probabilities, 1)

            if return_confidence:
                return predicted.item(), confidence.item()
            
            return predicted.item()
        
    def predict_batch(self, image_paths: List[str], return_confidence: bool = False) -> Union[List[int], List[Tuple[int, float]]]:
        """
        Make predictions on a batch of images
        Args:
            image_paths: List of paths to image files
            return_confidence: Whether to return confidence scores

        Returns:
            List of predicted classes (and confidence scores if return_confidence=True)
             
        """
        # Preprocess all images
        batch_tensors = []
        for image_path in image_paths:
            image_tensor = self.preprocess_image(image_path)
            batch_tensors.append(image_tensor)

        # Stack all tensors into a single batch
        batch = torch.cat(batch_tensors, dim=0)

        with torch.no_grad():
            # Get model predictions
            outputs = self.model(batch)
            probabilities = F.softmax(outputs, dim=1)

            # Get predicted classes and confidences
            confidence, predicted = torch.max(probabilities, 1)

            if return_confidence:
                return list(zip(predicted.cpu().numpy(), confidence.cpu().numpy()))
            return predicted.cpu().tolist()
        
    def get_top_k_predictions(self, image_path: str, k: int=3) -> List[Tuple[int, float]]:
        """
        Get top-k predictions for a single image
        Args:
            image_path: Path to the image file
            k: Number of top predicitons to return 

        Returns:
            List of (class, probability) tuples for top-k predictions
        """
        # Preprocess image
        image_tensor = self.preprocess_image(image_path)

        with torch.no_grad():
            # Get model prediciton
            outputs = self.model(image_tensor)
            probabilities = F.softmax(outputs, dim=1)

            # Get top-k predicitons
            top_prob, top_class = torch.topk(probabilities, k)

            return list(zip(top_class[0].cpu().numpy(), top_prob[0].cpu().numpy()))
        








=== ./main.py ===
import os
from train import train
from inference import LeNet5Inferencer



WEIGHTS_PATH = "/weights/lenet5.pth"
if os.path.exists(os.getcwd() + WEIGHTS_PATH):
    print(f"Using exisiting weights at {WEIGHTS_PATH}")
    pass
else:
    print("Weights do not exist, initializing training")
    train()


inferencer = LeNet5Inferencer("." + WEIGHTS_PATH)

image_path = "/Users/emadsiddiq/Downloads/BvH4E.png"

def make_prediction(image_path):
    prediction, confidence = inferencer.predict_single(image_path, return_confidence=True)
    print(f"Predicted digit: {prediction} with confidence: {confidence:.2f}")
    # Get top-3 predictions
    top_predictions = inferencer.get_top_k_predictions(image_path, k=3)
    print("\nTop 3 predictions:")
    for digit, prob in top_predictions:
        print(f"Digit {digit}: {prob:.2f}")


if os.path.exists(image_path):
    make_prediction(image_path)
else:
    print(f"Image path {image_path} doesn't exist")

from flask import Flask, request, jsonify
import logging


logging.basicConfig(level=logging.DEBUG)
app = Flask(__name__)

@app.route("/infer", methods=["POST"])
def handler():
    if request.method == "POST":
        data = request.get_json()  # Parse JSON payload
        img_path = data.get("img_path")  # Extract 'img_path'

        if not img_path:
            return jsonify({"error": "img_path is required"}), 400
        
        make_prediction(img_path)

        # Process the img_path here as needed
        return jsonify({"message": f"Received img_path: {img_path}"})

if __name__ == "__main__":
    app.run(debug=True)


